{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape and Parse Text From Websites\n",
    "\n",
    "Collecting data from websites using an automated process is known as web scraping. The primary language of information on the Internet is HTML (HyperText Markup Language), which is how most webpages are displayed in browsers. For instance, if you browse to a particular website and choose to \"view page source\" in your browser, you will most likely be presented with HTML code underlying that webpage; this is the information that your browser receives and translates into the page you actually see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspar y analizar texto de sitios web\n",
    "\n",
    "Recolectar datos de sitios web usando un proceso automatizado se conoce como raspado web. El idioma principal de información en Internet es HTML (HyperText Markup Language), que es la forma en que la mayoría de las páginas web se muestran en los navegadores. Por ejemplo, si navega a un sitio web en particular y elige \"ver el origen de la página\" en su navegador, lo más probable es que se le presente el código HTML subyacente a esa página web; esta es la información que su navegador recibe y traduce a la página que realmente ve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by grabbing all of the HTML code from a single webpage. We'll take a very\n",
    "simple page that's been set up just for practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos por obtener todo el código HTML de una sola página web. Tomaremos un muy\n",
    "página simple que se ha configurado solo para la práctica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Collect and parse first page\n",
    "page = requests.get('https://realpython.com/practice/aphrodite.html')\n",
    "mysoup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can parse data out of   my_soup   in various useful ways depending on what\n",
    "information we want. For instance, BeautifulSoup includes a   get_text()  method for\n",
    "extracting just the text from a document, removing any HTML tags automatically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí, podemos analizar los datos de my_soup de varias maneras útiles dependiendo de qué\n",
    "información que queremos Por ejemplo, BeautifulSoup incluye un método get_text () para\n",
    "extrayendo solo el texto de un documento, eliminando cualquier etiqueta HTML automáticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysoup.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mysoup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mysoup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of extra blank lines left, but these can always be taken out using the\n",
    "string   replace()   method. If we only want to get specific text from an HTML document,\n",
    "using Beautiful Soup to extract the text first and then using   find()   is sometimes easier\n",
    "than working with regular expressions.\n",
    "However, sometimes the HTML tags are actually the elements that point out the data we want to retrieve. For instance, perhaps we want to retrieve links for all the images on the page, which will appear in   <img>   HTML tags. In this case, we can use the   find_all() method to return a list of all instances of that particular tag:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas líneas en blanco adicionales, pero estas siempre se pueden sacar usando el\n",
    "método string replace (). Si solo queremos obtener texto específico de un documento HTML,\n",
    "usar Beautiful Soup para extraer el texto primero y luego usar find () es a veces más fácil\n",
    "que trabajar con expresiones regulares.\n",
    "Sin embargo, a veces las etiquetas HTML son en realidad los elementos que señalan los datos que queremos recuperar. Por ejemplo, quizás deseemos recuperar enlaces para todas las imágenes en la página, que aparecerán en <img> etiquetas HTML. En este caso, podemos usar el método find_all () para devolver una lista de todas las instancias de esa etiqueta en particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mysoup.find_all(\"img\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mysoup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or get a list of all european MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('http://www.europarl.europa.eu/meps/en/full-list.html')\n",
    "mysoup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(mysoup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mep_name = mysoup.find(class_='mep_name')\n",
    "print(mep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mep_name = mysoup.find_all(class_='mep_name')\n",
    "print(mep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in  mep_name:\n",
    "    print(name.find('a').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
